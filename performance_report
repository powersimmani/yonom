시간	시퀀스번호	에너지 소모율	속도	RPM	에어컨	냉각수온	브레이크	악셀개도량	휠각도	기어단수	광역시도	FFT_a	FFT_r	FFT_i	DWT_a	DWT_d	ave1	ave5	ave9	ave13	ave17	delta1	delta5	delta9	delta13	delta17
0	1	2	3	4	5	6	7	8	9	10	11	12	13	14	15	16	17	18	19	20	21	22	23	24	25	26



#CART

========================================
	all data 데이터의 10%를 테스트 데이터로 활
	accuracy : 0.909153787038
	f1_score : 0.406272671466
	roc_auc  : 0.83666710271
	precision: 0.277544796035
	recall   : 0.757701915071
	----------------------------------------
	y_pred_all_true
	accuracy : 0.757701915071
	----------------------------------------
	y_pred_all_false
	accuracy : 0.91563229035

	#CART
	========================================
	#all data(test 데이터 수가 반반(true, false)) 각 4500개
	#accuracy : 0.5
	#f1_score : 0.597207303974
	#roc_auc  : 0.5
	#precision: 0.5
	#recall   : 0.741333333333
	#----------------------------------------
	#y_pred_all_true
	#accuracy : 0.741333333333
	#----------------------------------------
	#y_pred_all_false
	#accuracy : 0.994888888889
	#----------------------------------------


	#logistic regression 데이터의 10%를 테스트 데이터로 활
	========================================
	iteration: 1 done
	----------------------------------------
	all data
	accuracy : 0.963350695927
	f1_score : 0.23873714083
	roc_auc  : 0.569329003548
	precision: 0.806954436451
	recall   : 0.140091590341
	----------------------------------------
	y_pred_all_true
	accuracy : 0.140091590341
	----------------------------------------
	y_pred_all_false
	accuracy : 0.998566416754
	----------------------------------------

	#logistic regression(test 데이터 수가 반반(true, false)) 각 4500개
	#----------------------------------------
	#all data
	#accuracy : 0.5
	#f1_score : 0.205227834687
	#roc_auc  : 0.5
	#precision: 0.5
	#recall   : 0.129111111111
	#----------------------------------------
	#y_pred_all_true
	#accuracy : 0.129111111111
	#----------------------------------------
	#y_pred_all_false
	#accuracy : 1.0
	#----------------------------------------



	false가 너무 많다 .

	precision 이 매우 낮다. -> 





Random Forestscore  			   		: 0.959115361626,	 11.7279281616 6초
AdaBoostscore       				    : 0.966629664418,	 84.1448380947 60초
Linear Discriminant Analysisscore    	: 0.96512680386,	 88.6847109795 4초
Quadratic Discriminant Analysisscore    : 0.964486380326,	 91.1678051949 3초




========================================
Random Forest
best score    : 0.961155956827
best params    : {}
grid score    : [mean: 0.96116, std: 0.00184, params: {}]
Random Forest done, takes 264.860424042
========================================
��^[[D^[[D^[[D^[[C========================================
AdaBoost
best score    : 0.955412985396
best params    : {}
grid score    : [mean: 0.95541, std: 0.00823, params: {}]
AdaBoost done, takes 448.572828054
========================================
========================================
Linear Discriminant Analysis
best score    : 0.950096965419
best params    : {}
grid score    : [mean: 0.95010, std: 0.02022, params: {}]
Linear Discriminant Analysis done, takes 257.353659153
========================================
========================================
Quadratic Discriminant Analysis
best score    : 0.936607197073
best params    : {}
grid score    : [mean: 0.93661, std: 0.03524, params: {}]
Quadratic Discriminant Analysis done, takes 248.230351925
========================================



feature 11개 짜리 성능
	========================================
	all data 데이터의 10%를 테스트 데이터로 활
	accuracy : 0.909153787038
	f1_score : 0.406272671466
	roc_auc  : 0.83666710271
	precision: 0.277544796035
	recall   : 0.757701915071
	----------------------------------------
	6초 걸림

	이건 두번째 성능인데 이상하다. 이상하게 precision이 높다.
	---------------------------------------
	all data
	accuracy : 0.959918025788
	f1_score : 0.04477004477
	roc_auc  : 0.511448792673
	precision: 1.0
	recall   : 0.0228975853455
	----------------------------------------
	Random Forest done, takes 7.7576520443
	[ 1  1 -1 ..., -1 -1 -1]
	----------------------------------------
	all data
	accuracy : 0.96512680386
	f1_score : 0.378575776019
	roc_auc  : 0.62714252527
	precision: 0.703619909502
	recall   : 0.258950874271
	----------------------------------------
	Linear Discriminant Analysis done, takes 3.05206394196
	[ 1  1  1 ..., -1 -1 -1]
	----------------------------------------
	all data
	accuracy : 0.964486380326
	f1_score : 0.554185872012
	roc_auc  : 0.76040951136
	precision: 0.571270718232
	recall   : 0.53809325562
	----------------------------------------
	Quadratic Discriminant Analysis done, takes 2.1589550972


feature 45개 짜리 성능
	----------------------------------------                           
	all data precision이 아주 좋으나 recall이 또 너무 작다 -------- feature 45개 cart
	accuracy : 0.959029971821
	f1_score : 0.0024948024948
	roc_auc  : 0.5006244796
	precision: 1.0
	recall   : 0.00124895920067
	----------------------------------------
	Random Forest done, takes 46.7152488232

	----------------------------------------
	all data -> 시간은 오래걸리지만 성능이 괜찮게 나왔다. ------- feature 45개 adaboost
	accuracy : 0.976867901973
	f1_score : 0.716898317484
	roc_auc  : 0.851050588812
	precision: 0.719832109129
	recall   : 0.713988343047
	----------------------------------------
	AdaBoost done, takes 1378.34906816
	----------------------------------------
	all data
	accuracy : 0.97509179404
	f1_score : 0.619339684197
	roc_auc  : 0.744817950697
	precision: 0.830010493179
	recall   : 0.493963363863
	----------------------------------------
	Linear Discriminant Analysis done, takes 92.1821169853

	all data
	accuracy : 0.758714029545
	f1_score : 0.190134991832
	roc_auc  : 0.726049836289
	precision: 0.11024695051
	recall   : 0.690466278102
	----------------------------------------
	Quadratic Discriminant Analysis done, takes 80.0259270668

	전반적으로 precision, recall 이 반전되었다. 즉 feature selection을 통해 성능향상이 가능하진다.



feature 45개 중 DFT와 DWT만을 이용해 만든 성능

	all data    랜덤 포레스트 전체 -1리턴으로 성능측정 불가 
	accuracy : 0.958978737939
	f1_score : 0.0
	roc_auc  : 0.5
	precision: 0.0
	recall   : 0.0
	----------------------------------------
	Random Forest done, takes 13.3707230091
	[ 1  1  1 ..., -1 -1 -1]
	----------------------------------------
	all data
	accuracy : 0.967253009991
	f1_score : 0.434449196284
	roc_auc  : 0.651065872454
	precision: 0.745068285281
	recall   : 0.306619483764
	----------------------------------------
	Linear Discriminant Analysis done, takes 8.53555297852

	all data
	accuracy : 0.967253009991
	f1_score : 0.434449196284
	roc_auc  : 0.651065872454
	precision: 0.745068285281
	recall   : 0.306619483764
	----------------------------------------
	AdaBoost done, takes 7.37015008926
	[ 1 -1  1 ..., -1 -1 -1]
	----------------------------------------
	all data


	[ 1 -1  1 ..., -1 -1 -1]
	----------------------------------------
	all data 
	accuracy : 0.854034668261
	f1_score : 0.184290895209
	roc_auc  : 0.6376647261
	precision: 0.119551758296
	recall   : 0.401956702748
	----------------------------------------
	Quadratic Discriminant Analysis done, takes 8.81193804741

delta 와 sum만을 이용해 만든 성능

	all data
	accuracy : 0.959286141235
	f1_score : 0.0148760330579
	roc_auc  : 0.503746877602
	precision: 1.0
	recall   : 0.007493755204
	----------------------------------------
	Random Forest done, takes 14.3266329765 
	[ 1  1  1 ..., -1 -1 -1]
	----------------------------------------
	
	----------------------------------------
all data
accuracy : 0.974861241568
f1_score : 0.614356824731
roc_auc  : 0.741908164684
precision: 0.828621908127
recall   : 0.488134887594
----------------------------------------
AdaBoost done, takes 17.9752469063


	[1 1 1 ..., 1 1 1]
	----------------------------------------
	all data
	accuracy : 0.101502860558
	f1_score : 0.0802104913504
	roc_auc  : 0.510014772
	precision: 0.0418632236872
	recall   : 0.955037468776
	----------------------------------------
	Quadratic Discriminant Analysis done, takes 20.8545300961


